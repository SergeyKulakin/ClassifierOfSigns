#ClassifierOfSigns
Scientific research seminar project

- постановка задачи (цель, метрики и тд)
Цель исследования - оценка качества классификации изображений дорожных знаков с применением классических методов машинного обучения.
https://drive.google.com/drive/folders/1Dy3xREmKdPzN-Lftn-wyrOBWBr8c775z  - ссылка на собранную выборку данных


- описание процесса сбора данных (описание классов, обоснование почему их столько)
Сбор данных проводился при помощи смартфона, фотографии делались в светлое время дня. 
После сбора данных проводилась подготовка изображений: изображение обрезалось (в центре должен находится знак с минимальным кол-во посторонней информации),
изменялся размер изображения до разрешения 224х224 пикселя.
Всего существует 8 типов дорожных знаков:
    1 предупреждающие; (в основном треугольные знаки с красной окантовкой и чёрным изображением внутри) 84 изображения
    2 знаки приоритета; (прямоугольные, треугольные, круглые знаки с красной и белой окантовкой, возможно заливка жёлтым ) 35 изображения
	3 запрещающие; (Круглые знаки с красной окантовкой, встречается жёлтая и синяя заливки по середине знака) 124 изображения
    4 предписывающие; (Круглые знаки с синей заливкой и белыми изображениями) 37 изображений
    5 особые предписания; (прямоугольные знаки с синей заливкой и чёрно-белыми изображениями) 150 изображений
    6 информационные; (Прямоугольные знаки с синей, желтой, зелёной заливками и белыми надписями) 81 изображение
    7 сервисные; (прямоугольные знаки с белым окном и чёрным изображением)  28 изображений
    8 с дополнительной информацией. (белые прямоугольные знаки с черными изображениями и текстом) 148 изображениями


- описание  моделей (baseline)
	Все изображения цветные и имеют три цветовых канала. Следовательно, имеет смысл составить ансамбль из трёх моделей для повышения качества.
	На перечисленных ниже моделях применялись различные подходы при обучении, где-то использовалась серые пиксели в качестве признаков, 
	где-то изображение разбивалось на цветовые каналы. Ниже представленны результаты моделирования.
	
	линейная регрессия score: по каналам с PCA - 0.8454;
	random forest score: по каналам - 0.807, по каналам c PCA - 0.801;
	GB (catboost, xgboost, lightgbm) score: catboost(серый) - 0.777,  xgboost(серый) - 0.7536, lgbm(серый) - 0.7971;
	KNN score: серый 0.734, по каналам с PCA - 0.8309;
	SVC(kernel=‘linear’) score: серый - 0.831.

	После обучения были сделаны следующие выводы:
	хуже всех модельки обучаются на 1 канале (красный цвет);
	лучше всех на голубом;
	на SVC и RandomForest суммарная модель показывает лучшие результаты чем на отдельных каналах (проверить на стабильность);
	лучший результат у SVC (0.84);
	при снижении размерности в 500 раз качество у KNeighbors и CatBoost выросло;
	обучение моделей с использованием PCA происходит быстрее, особенно в случае CatBoost.

- план по улучшению baseline
	убрать шумовую составляющую фона;
	уменьшить кол-во признаков у объекта (методы снижения размерности) //частично выполнено;
	провести оптимизацию гиперпараметров (например в optuna);
	увеличить выборку через аугментацию;